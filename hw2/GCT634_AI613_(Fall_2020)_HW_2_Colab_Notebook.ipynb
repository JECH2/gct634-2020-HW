{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C34u1Fk_d855"
   },
   "source": [
    "# Homework #2: Music Genre Classification\n",
    "Music genre classification is an important task that can be used in many musical applications such as music search or recommender systems. Your mission is to build your own Convolutional Neural Network (CNN) model to classify audio files into different music genres. Specifically, the goals of this homework are as follows:\n",
    "\n",
    "* Experiencing the whole pipeline of deep learning based system: data preparation, feature extraction, model training and evaluation\n",
    "* Getting familiar with the CNN architectures for music classification tasks\n",
    "* Using Pytorch in practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jS4CjH2Ocshx"
   },
   "source": [
    "# Getting Ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8uXpEzF6HIry"
   },
   "source": [
    "## Installing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "WuoI2dH5JEML"
   },
   "outputs": [],
   "source": [
    "#!pip install musicnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5i1Y0_-cXv5"
   },
   "source": [
    "## Preparing The Dataset\n",
    "We use the [GTZAN](http://marsyas.info/downloads/datasets.html) dataset which has been the most widely used in the music genre classification task. \n",
    "The dataset contains 30-second audio files including 10 different genres including reggae, classical, country, jazz, metal, pop, disco, hiphop, rock and blues. \n",
    "For this homework, we are going to use a subset of GTZAN with only 8 genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "kWuczGYl9sB3"
   },
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "#!gdown --id 1J1DM0QzuRgjzqVWosvPZ1k7MnBRG-IxS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "xEL8yjcO9zTs"
   },
   "outputs": [],
   "source": [
    "# Uncompress the dataset\n",
    "#!tar zxf gtzan.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMdtGjitcptx"
   },
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "SwAowYXSQSky"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.notebook import tqdm\n",
    "from glob import glob\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NyC0UrXH-Uh6"
   },
   "source": [
    "## Enabling and testing the GPU\n",
    "\n",
    "First, you'll need to enable GPUs for the Colab notebook:\n",
    "\n",
    "- Navigate to Edit (수정) → Notebook Settings (노트 설정)\n",
    "- select GPU from the Hardware Accelerator (하드웨어 가속기) drop-down\n",
    "\n",
    "Next, we'll confirm that we can connect to the GPU with PyTorch and check versions of packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "s3RwC1lh-bCx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: GeForce GTX 1080\n",
      "PyTorch version: 1.6.0\n",
      "Librosa version: 0.8.0\n"
     ]
    }
   ],
   "source": [
    "if not torch.cuda.is_available():\n",
    "  raise SystemError('GPU device not found!')\n",
    "print(f'Found GPU at: {torch.cuda.get_device_name()}')\n",
    "print(f'PyTorch version: {torch.__version__}')\n",
    "print(f'Librosa version: {librosa.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  444\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "manualSeed = 444\n",
    "    #manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "np.random.seed(manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "torch.cuda.manual_seed(manualSeed)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1IrP3qHvQuYi"
   },
   "source": [
    "If the cell above throws an error, then you should enable the GPU following the instruction above!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UEyf5th3zodi"
   },
   "source": [
    "# Training CNNs from Scratch\n",
    "\n",
    "The baseline code is provided so that you can easily start the homework and also compare with your own algorithm.\n",
    "The baseline model extracts mel-spectrogram and has a simple set of CNN model that includes convolutional layer, batch normalization, maxpooling and fully-connected layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jLEXvCXUK6GR"
   },
   "source": [
    "## Extracting Mel-spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "FgjbChF0znXt"
   },
   "outputs": [],
   "source": [
    "# Mel-spectrogram setup.\n",
    "SR = 16000\n",
    "FFT_HOP = 512\n",
    "FFT_SIZE = 1024\n",
    "NUM_MELS = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "TAjStuDUI1Wb"
   },
   "outputs": [],
   "source": [
    "genres = genres = ['classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae']\n",
    "genre_dict = {g: i for i, g in enumerate(genres)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "19CimidPW0g1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(580, 150)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_split(path):\n",
    "  with open(path) as f:\n",
    "    paths = [line.rstrip('\\n') for line in f]\n",
    "  return paths\n",
    "\n",
    "train = load_split('gtzan/split/train.txt')\n",
    "test = load_split('gtzan/split/test.txt')\n",
    "\n",
    "# Each entry of the lists look like this:\n",
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "vs179N8UXrrx"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f8ead1f85784ed2806dac7c0afbc2b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=730.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Make directories to save mel-spectrograms.\n",
    "for genre in genres:\n",
    "  os.makedirs('gtzan/spec/' + genre, exist_ok=True)\n",
    "  \n",
    "for path_in in tqdm(train + test):\n",
    "  # The spectrograms will be saved under `gtzan/spec/` with an file extension of `.npy`\n",
    "  path_out = 'gtzan/spec/' + path_in.replace('.wav', '.npy')\n",
    "\n",
    "  # Skip if the spectrogram already exists\n",
    "  if os.path.isfile(path_out):\n",
    "    continue\n",
    "    \n",
    "  # Load the audio signal with the desired sampling rate (SR).\n",
    "  sig, _ = librosa.load(f'gtzan/wav/{path_in}', sr=SR, res_type='kaiser_fast')\n",
    "  # Compute power mel-spectrogram.\n",
    "  melspec = librosa.feature.melspectrogram(sig, sr=SR, n_fft=FFT_SIZE, hop_length=FFT_HOP, n_mels=NUM_MELS)\n",
    "  # Transform the power mel-spectrogram into the log compressed mel-spectrogram.\n",
    "  melspec = librosa.power_to_db(melspec)\n",
    "  # \"float64\" uses too much memory! \"float32\" has enough precision for spectrograms.\n",
    "  melspec = melspec.astype('float32')\n",
    "\n",
    "  # Save the spectrogram.\n",
    "  np.save(path_out, melspec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LykkQw0eLDWJ"
   },
   "source": [
    "## Defining a dataset of spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "L6YDccHNLdI1"
   },
   "outputs": [],
   "source": [
    "# Data processing setup.\n",
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "HfeuWIyfiSsD"
   },
   "outputs": [],
   "source": [
    "class SpecDataset(Dataset):\n",
    "  def __init__(self, paths, mean=0, std=1, time_dim_size=None):\n",
    "    self.paths = paths\n",
    "    self.mean = mean\n",
    "    self.std = std\n",
    "    self.time_dim_size = time_dim_size\n",
    "\n",
    "  def __getitem__(self, i):\n",
    "    # Get i-th path.\n",
    "    path = self.paths[i]\n",
    "    # Get i-th spectrogram path.\n",
    "    path = 'gtzan/spec/' + path.replace('.wav', '.npy')\n",
    "\n",
    "    # Extract the genre from its path.\n",
    "    genre = path.split('/')[-2]\n",
    "    # Trun the genre into index number.\n",
    "    label = genre_dict[genre]\n",
    "\n",
    "    # Load the mel-spectrogram.\n",
    "    spec = np.load(path)\n",
    "    if self.time_dim_size is not None:\n",
    "      # Slice the temporal dimension with a fixed length so that they have\n",
    "      # the same temporal dimensionality in mini-batches.\n",
    "      spec = spec[:, :self.time_dim_size]\n",
    "    # Perform standard normalization using pre-computed mean and std.\n",
    "    spec = (spec - self.mean) / self.std\n",
    "\n",
    "    return spec, label\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7mZxLEgJ6ON"
   },
   "source": [
    "### Computing statistics of the training set\n",
    "The code below compute mean, standard deviation and the minimum temporal dimension size, and use them for preprocessing inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ZSNZ81-0nbWp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(936, -18.100582, 16.520634)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load all spectrograms.\n",
    "dataset_train = SpecDataset(train)\n",
    "specs = [s for s, _ in dataset_train]\n",
    "# Compute the minimum temporal dimension size.\n",
    "time_dims = [s.shape[1] for s in specs]\n",
    "min_time_dim_size = min(time_dims)\n",
    "# Stack the spectrograms\n",
    "specs = [s[:, :min_time_dim_size] for s in specs]\n",
    "specs = np.stack(specs)\n",
    "# Compute mean and standard deviation for standard normalization.\n",
    "mean = specs.mean()\n",
    "std = specs.std()\n",
    "\n",
    "min_time_dim_size, mean, std, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S6pspUSkKpYc"
   },
   "source": [
    "### Creating datasets and data loaders using the pre-computed statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "L6iSe9gni2M1"
   },
   "outputs": [],
   "source": [
    "dataset_train = SpecDataset(train, mean, std, min_time_dim_size)\n",
    "dataset_test = SpecDataset(test, mean, std, min_time_dim_size)\n",
    "\n",
    "num_workers = os.cpu_count()\n",
    "# the drop_last argument drops the last non-full batch of each worker’s dataset replica.\n",
    "loader_train = DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers, drop_last=True)\n",
    "loader_test = DataLoader(dataset_test, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DbODI4qpWYeo"
   },
   "source": [
    "## Training a baseline\n",
    "The table below shows the architecture of the baseline.\n",
    "\n",
    "| Layer          | Output Size | Details                 |\n",
    "|----------------|-------------|-------------------------|\n",
    "| conv           | 32 x 936    | kernel_size=7, stride=1 |\n",
    "| maxpool        | 32 x 133    | kernel_size=7, stride=7 |\n",
    "| conv           | 32 x 133    | kernel_size=7, stride=1 |\n",
    "| maxpool        | 32 x 19     | kernel_size=7, stride=7 |\n",
    "| conv           | 32 x 19     | kernel_size=7, stride=1 |\n",
    "| maxpool        | 32 x 2      | kernel_size=7, stride=7 |\n",
    "| global_avgpool | 32 x 1      | -                       |\n",
    "\n",
    "The class below is an implementation of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "P2ZC-xNf2sgF"
   },
   "outputs": [],
   "source": [
    "class Baseline(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Baseline, self).__init__()\n",
    "\n",
    "    self.conv0 = nn.Sequential(\n",
    "      nn.Conv1d(NUM_MELS, out_channels=32, kernel_size=7, stride=1, padding=3),\n",
    "      nn.BatchNorm1d(32),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool1d(kernel_size=7, stride=7)\n",
    "    )\n",
    "\n",
    "    self.conv1 = nn.Sequential(\n",
    "      nn.Conv1d(32, out_channels=32, kernel_size=7, stride=1, padding=3),\n",
    "      nn.BatchNorm1d(32),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool1d(kernel_size=7, stride=7)\n",
    "    )\n",
    "\n",
    "    self.conv2 = nn.Sequential(\n",
    "      nn.Conv1d(32, out_channels=32, kernel_size=7, stride=1, padding=3),\n",
    "      nn.BatchNorm1d(32),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool1d(kernel_size=7, stride=7)\n",
    "    )\n",
    "\n",
    "    # Aggregate features over temporal dimension.\n",
    "    self.final_pool = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "    # Predict genres using the aggregated features.\n",
    "    self.linear = nn.Linear(32, len(genres))\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.conv0(x)\n",
    "    x = self.conv1(x)\n",
    "    x = self.conv2(x)\n",
    "    x = self.final_pool(x)\n",
    "    x = self.linear(x.squeeze(-1))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "g2fCKvL70Ydr"
   },
   "outputs": [],
   "source": [
    "# Training setup.\n",
    "LR = 0.0006  # learning rate\n",
    "MOMENTUM = 0.9\n",
    "NUM_EPOCHS = 20\n",
    "weight_decay = 0.0  # L2 regularization weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ChMVPF0XkmAu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Baseline(\n",
       "  (conv0): Sequential(\n",
       "    (0): Conv1d(96, 32, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool1d(kernel_size=7, stride=7, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool1d(kernel_size=7, stride=7, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool1d(kernel_size=7, stride=7, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (final_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Baseline()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "GbzPhKsz01ZX"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-ff60dcdf331c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Setup an optimizer. Here, we use Stochastic gradient descent (SGD) with a nesterov mementum.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMOMENTUM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# Choose a device. We will use GPU if it's available, otherwise CPU.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Define a loss function, which is cross entropy here.\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# Setup an optimizer. Here, we use Stochastic gradient descent (SGD) with a nesterov mementum.\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=MOMENTUM, nesterov=True, weight_decay=weight_decay)\n",
    "# Choose a device. We will use GPU if it's available, otherwise CPU.\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# Move variables to the desired device.\n",
    "model.to(device)\n",
    "criterion.to(device)\n",
    "\n",
    "print(f'Optimizer: {optimizer}')\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ABFnD3tN2CRw"
   },
   "outputs": [],
   "source": [
    "# Util function for computing accuracy.\n",
    "def accuracy(source, target):\n",
    "  source = source.max(1)[1].long().cpu()\n",
    "  target = target.cpu()\n",
    "  correct = (source == target).sum().item()\n",
    "  return correct / float(source.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "2DBAh6pskuaY"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8300801e62f46feb3d67680baf58d32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 00', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "854b3cf0591f4c7bbab3b539fe8168c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 01', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32bcdfeff0ff45758ec0096ae5861316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 02', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0330d93251bd4ff89603969cba78b7b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 03', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "646792cd54e041cc9132c14b38c2ce6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 04', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "826747cbcc3a49f39ec4f105ad25e641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 05', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b7e1152257442718b5d691ebfdafa31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 06', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36d2d459a5c54b28b90ef57d1d859285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 07', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba514359f3cd43f6b0ddcbe70b6b4b7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 08', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32ff0e2352144d1a8f8f50920cd658b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 09', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d37f3f07e3fc4338a338c77349416b13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 10', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b3814275644404099031ad92b0cd681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 11', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dafc00a621c480b87fbd05099da1d32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 12', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f815b810f2c48da92b5bf4c2a609bc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 13', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9fa5884fdc44c4e92d2f794d9f0453e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 14', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "406dceab64504258af99d624470c024f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 15', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f68f427861c14ec1a06009c42e629d58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 16', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60c3636cc9da4703a3215556db621f03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 17', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeeaddfe0f7f47b982a72fac06e62507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 18', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa1e728fbd414e94bd58dd290c40a227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 19', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the status of the model as training.\n",
    "model.train()\n",
    "\n",
    "# Iterate over epochs.\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "  epoch_loss = 0\n",
    "  epoch_acc = 0\n",
    "  pbar = tqdm(loader_train, desc=f'Epoch {epoch:02}')  # progress bar\n",
    "  for x, y in pbar:\n",
    "    # Move mini-batch to the desired device.\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    # Feed forward the model.\n",
    "    prediction = model(x)\n",
    "    # Compute the loss.\n",
    "    loss = criterion(prediction, y)\n",
    "    # Compute the accuracy.\n",
    "    acc = accuracy(prediction, y)\n",
    "\n",
    "    # Perform backward propagation to compute gradients.\n",
    "    loss.backward()\n",
    "    # Update the parameters.\n",
    "    optimizer.step()\n",
    "    # Reset the computed gradients.\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Log training metrics.\n",
    "    batch_size = len(x)\n",
    "    epoch_loss += batch_size * loss.item()\n",
    "    epoch_acc += batch_size * acc\n",
    "    # Update the progress bar.\n",
    "    pbar.set_postfix({'loss': epoch_loss / len(dataset_train), \n",
    "                      'acc': epoch_acc / len(dataset_train)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "ZsaLepTZk8RF"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5104b92a599344ba89e12f532ca5185f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Test', max=38.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test_loss=1.07690, test_acc=58.67%\n"
     ]
    }
   ],
   "source": [
    "# Set the status of the model as evaluation.\n",
    "model.eval()\n",
    "\n",
    "# `torch.no_grad()` disables computing gradients. The gradients are still \n",
    "# computed even though you use `model.eval()`. You should use `torch.no_grad()` \n",
    "# if you don't want your memory is overflowed because of unnecesary gradients.\n",
    "with torch.no_grad():\n",
    "  epoch_loss = 0\n",
    "  epoch_acc = 0\n",
    "  pbar = tqdm(loader_test, desc=f'Test')  # progress bar\n",
    "  for x, y in pbar:\n",
    "    # Move mini-batch to the desired device.\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    # Feed forward the model.\n",
    "    prediction = model(x)\n",
    "    # Compute the loss.\n",
    "    loss = criterion(prediction, y)\n",
    "    # Compute the accuracy.\n",
    "    acc = accuracy(prediction, y)\n",
    "\n",
    "    # Log training metrics.\n",
    "    batch_size = len(x)\n",
    "    epoch_loss += batch_size * loss.item()\n",
    "    epoch_acc += batch_size * acc\n",
    "    # Update the progress bar.\n",
    "    pbar.set_postfix({'loss': epoch_loss / len(dataset_test), 'acc': epoch_acc / len(dataset_test)})\n",
    "\n",
    "# Compute the evaluation scores.\n",
    "test_loss = epoch_loss / len(dataset_test)\n",
    "test_acc = epoch_acc / len(dataset_test)\n",
    "\n",
    "print(f'test_loss={test_loss:.5f}, test_acc={test_acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L3Zwk73MGHmx"
   },
   "source": [
    "### [Question 1] Implement the given architecture.\n",
    "Implement a CNN with the architecture below, train, and report a test accuracy of the CNN.\n",
    "\n",
    "| Layer          | Output Size | Details                 |\n",
    "|----------------|-------------|-------------------------|\n",
    "| conv           | 16 x 936    | kernel_size=7, stride=1 |\n",
    "| maxpool        | 16 x 133    | kernel_size=7, stride=7 |\n",
    "| conv           | 32 x 133    | kernel_size=5, stride=1 |\n",
    "| maxpool        | 32 x 26     | kernel_size=5, stride=5 |\n",
    "| conv           | 64 x 26     | kernel_size=3, stride=1 |\n",
    "| maxpool        | 64 x 8      | kernel_size=3, stride=3 |\n",
    "| conv           | 128 x 8     | kernel_size=3, stride=1 |\n",
    "| maxpool        | 128 x 2     | kernel_size=3, stride=3 |\n",
    "| global_avgpool | 32 x 1      | -                       |\n",
    "\n",
    "Note: you should give appropriate paddings! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "pjP6-Q6Lhqwi"
   },
   "outputs": [],
   "source": [
    "# TODO: Question 1\n",
    "## (L_in + 2p - (k - 1) - 1)/s + 1 = L_out\n",
    "class Q1(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Q1, self).__init__()\n",
    "\n",
    "    self.conv0 = nn.Sequential(\n",
    "      nn.Conv1d(NUM_MELS, out_channels=16, kernel_size=7, stride=1, padding=3),\n",
    "      nn.BatchNorm1d(16),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool1d(kernel_size=7, stride=7)\n",
    "    )\n",
    "\n",
    "    self.conv1 = nn.Sequential(\n",
    "      nn.Conv1d(16, out_channels=32, kernel_size=5, stride=1, padding=2),\n",
    "      nn.BatchNorm1d(32),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool1d(kernel_size=5, stride=5)\n",
    "    )\n",
    "\n",
    "    self.conv2 = nn.Sequential(\n",
    "      nn.Conv1d(32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "      nn.BatchNorm1d(64),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool1d(kernel_size=3, stride=3)\n",
    "    )\n",
    "\n",
    "    self.conv3 = nn.Sequential(\n",
    "      nn.Conv1d(64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "      nn.BatchNorm1d(128),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool1d(kernel_size=3, stride=3)\n",
    "    )\n",
    "    \n",
    "    # Aggregate features over temporal dimension.\n",
    "    self.final_pool = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "    # Predict genres using the aggregated features.\n",
    "    self.linear = nn.Linear(128, len(genres))\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.conv0(x)\n",
    "    x = self.conv1(x)\n",
    "    x = self.conv2(x)\n",
    "    x = self.conv3(x)\n",
    "    x = self.final_pool(x)\n",
    "    x = self.linear(x.squeeze(-1))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q1(\n",
       "  (conv0): Sequential(\n",
       "    (0): Conv1d(96, 16, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool1d(kernel_size=7, stride=7, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool1d(kernel_size=5, stride=5, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (final_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (linear): Linear(in_features=128, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q1_model = Q1()\n",
    "Q1_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.0006\n",
      "    momentum: 0.9\n",
      "    nesterov: True\n",
      "    weight_decay: 0.0\n",
      ")\n",
      "Device: cuda\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1              [-1, 16, 936]          10,768\n",
      "       BatchNorm1d-2              [-1, 16, 936]              32\n",
      "              ReLU-3              [-1, 16, 936]               0\n",
      "         MaxPool1d-4              [-1, 16, 133]               0\n",
      "            Conv1d-5              [-1, 32, 133]           2,592\n",
      "       BatchNorm1d-6              [-1, 32, 133]              64\n",
      "              ReLU-7              [-1, 32, 133]               0\n",
      "         MaxPool1d-8               [-1, 32, 26]               0\n",
      "            Conv1d-9               [-1, 64, 26]           6,208\n",
      "      BatchNorm1d-10               [-1, 64, 26]             128\n",
      "             ReLU-11               [-1, 64, 26]               0\n",
      "        MaxPool1d-12                [-1, 64, 8]               0\n",
      "           Conv1d-13               [-1, 128, 8]          24,704\n",
      "      BatchNorm1d-14               [-1, 128, 8]             256\n",
      "             ReLU-15               [-1, 128, 8]               0\n",
      "        MaxPool1d-16               [-1, 128, 2]               0\n",
      "AdaptiveAvgPool1d-17               [-1, 128, 1]               0\n",
      "           Linear-18                    [-1, 8]           1,032\n",
      "================================================================\n",
      "Total params: 45,784\n",
      "Trainable params: 45,784\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.34\n",
      "Forward/backward pass size (MB): 0.53\n",
      "Params size (MB): 0.17\n",
      "Estimated Total Size (MB): 1.05\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Define a loss function, which is cross entropy here.\n",
    "Q1_criterion = torch.nn.CrossEntropyLoss()\n",
    "# Setup an optimizer. Here, we use Stochastic gradient descent (SGD) with a nesterov mementum.\n",
    "Q1_optimizer = torch.optim.SGD(Q1_model.parameters(), lr=LR, momentum=MOMENTUM, nesterov=True, weight_decay=weight_decay)\n",
    "\n",
    "# Move variables to the desired device.\n",
    "Q1_model.to(device)\n",
    "Q1_criterion.to(device)\n",
    "\n",
    "print(f'Optimizer: {Q1_optimizer}')\n",
    "print(f'Device: {device}')\n",
    "\n",
    "from torchsummary import summary\n",
    "summary(Q1_model, (NUM_MELS, 936))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ca6604d07a649f3b1d4db8230587aeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 00', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89ac4bd434034e9f9946e4bca809d0d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 01', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07859332fde74125b49b75cf81e90970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 02', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "899500987186480d9e4d51105686458f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 03', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19cf7c023b1542fba3612f16f97f8467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 04', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcc1daa57f89457cbbc36cb16a8845f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 05', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ddb44e854ca4e829c922538d1ac1441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 06', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be5dd9de83574bb88ace7a07bfab6d5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 07', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0524617f9e46480898fdc6129b660d71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 08', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4f6cc30f6724b3485fc4b4d4cf71cef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 09', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bab1f1c130e476aa354f5d9084c1101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 10', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "874839376c234a67a32f000f0b8b0e17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 11', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26105af29d5248198058fb1c7ab6e8b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 12', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "def8f0403b4a4fbf91d6768f5cb9cdb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 13', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08aab4cb7b85495f81442547f3ee2f43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 14', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02688c530bc04848944429b58664ffd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 15', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9e1ef14f5a94f1f92c3868f8a5a6981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 16', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02eb387700c24c5292a01409660d4d62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 17', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d0447849d454cb389b34dd9719af562",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 18', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b328646d016427bb59aafaab33f7975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 19', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the status of the model as training.\n",
    "Q1_model.train()\n",
    "Q1_NUM_EPOCHS = 20\n",
    "# Iterate over epochs.\n",
    "for epoch in range(Q1_NUM_EPOCHS):\n",
    "  epoch_loss = 0\n",
    "  epoch_acc = 0\n",
    "  pbar = tqdm(loader_train, desc=f'Epoch {epoch:02}')  # progress bar\n",
    "  for x, y in pbar:\n",
    "    # Move mini-batch to the desired device.\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    # Feed forward the model.\n",
    "    prediction = Q1_model(x)\n",
    "    # Compute the loss.\n",
    "    loss = Q1_criterion(prediction, y)\n",
    "    # Compute the accuracy.\n",
    "    acc = accuracy(prediction, y)\n",
    "\n",
    "    # Perform backward propagation to compute gradients.\n",
    "    loss.backward()\n",
    "    # Update the parameters.\n",
    "    Q1_optimizer.step()\n",
    "    # Reset the computed gradients.\n",
    "    Q1_optimizer.zero_grad()\n",
    "\n",
    "    # Log training metrics.\n",
    "    batch_size = len(x)\n",
    "    epoch_loss += batch_size * loss.item()\n",
    "    epoch_acc += batch_size * acc\n",
    "    # Update the progress bar.\n",
    "    pbar.set_postfix({'loss': epoch_loss / len(dataset_train), \n",
    "                      'acc': epoch_acc / len(dataset_train)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1ef6ca64d96450096937d137e96a177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Test', max=38.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test_loss=1.19948, test_acc=60.67%\n"
     ]
    }
   ],
   "source": [
    "# Set the status of the model as evaluation.\n",
    "Q1_model.eval()\n",
    "\n",
    "# `torch.no_grad()` disables computing gradients. The gradients are still \n",
    "# computed even though you use `model.eval()`. You should use `torch.no_grad()` \n",
    "# if you don't want your memory is overflowed because of unnecesary gradients.\n",
    "with torch.no_grad():\n",
    "  epoch_loss = 0\n",
    "  epoch_acc = 0\n",
    "  pbar = tqdm(loader_test, desc=f'Test')  # progress bar\n",
    "  for x, y in pbar:\n",
    "    # Move mini-batch to the desired device.\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    # Feed forward the model.\n",
    "    prediction = Q1_model(x)\n",
    "    # Compute the loss.\n",
    "    loss = Q1_criterion(prediction, y)\n",
    "    # Compute the accuracy.\n",
    "    acc = accuracy(prediction, y)\n",
    "\n",
    "    # Log training metrics.\n",
    "    batch_size = len(x)\n",
    "    epoch_loss += batch_size * loss.item()\n",
    "    epoch_acc += batch_size * acc\n",
    "    # Update the progress bar.\n",
    "    pbar.set_postfix({'loss': epoch_loss / len(dataset_test), 'acc': epoch_acc / len(dataset_test)})\n",
    "\n",
    "# Compute the evaluation scores.\n",
    "test_loss = epoch_loss / len(dataset_test)\n",
    "test_acc = epoch_acc / len(dataset_test)\n",
    "\n",
    "print(f'test_loss={test_loss:.5f}, test_acc={test_acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VIRc_WML8MnD"
   },
   "source": [
    "# Exploiting Prior Knowledge using Pre-trained Models\n",
    "\n",
    "\n",
    "Someone who knows how to play acoustic guitars might be better at playing electric guitars than who never played a guitar.\n",
    "Here, we will use pre-trained models from [`musicnn`](https://github.com/jordipons/musicnn) (pronounced as \"musician\"), which includes CNNs already trained on a large amount of songs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bq4wDvyMTTOk"
   },
   "source": [
    "You can predict some tags with the pre-trained model like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "qQkmEKSXTfW5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing spectrogram (w/ librosa) and tags (w/ tensorflow).. done!\n",
      "[gtzan/wav/classical/classical.00030.wav] Top10 tags: \n",
      " - jazz\n",
      " - instrumental\n",
      " - Progressive rock\n",
      " - folk\n",
      " - ambient\n",
      " - rock\n",
      " - female vocalists\n",
      " - pop\n",
      " - electronic\n",
      " - easy listening\n"
     ]
    }
   ],
   "source": [
    "from musicnn.tagger import top_tags\n",
    "\n",
    "_ = top_tags('gtzan/wav/' + train[0], model='MSD_musicnn', topN=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dTo0E7zdThUm"
   },
   "source": [
    "However, the 10 tags are not what we want as outputs! Let's extract embedding (or features) using the pre-trained model, and train 2-layer MLP using the embeddings as inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iz0e6KvNTwMh"
   },
   "source": [
    "## Extracting embeddings using the pre-trained model\n",
    "\n",
    "Side note: this will take about 23 min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "1L-FJ-e5ISbg"
   },
   "outputs": [],
   "source": [
    "# from musicnn.extractor import extractor\n",
    "\n",
    "# # Make directories to save embeddings.\n",
    "# for genre in genres:\n",
    "#   os.makedirs('gtzan/msd_embed/' + genre, exist_ok=True)\n",
    "\n",
    "# for path_in in tqdm(train + test):\n",
    "#   # The embeddings will be saved under `gtzan/embed/` with an file extension of `.npy`\n",
    "#   path_out = 'gtzan/msd_embed/' + path_in.replace('.wav', '.npy')\n",
    "#   # Skip if the embedding already exists.\n",
    "#   if os.path.isfile(path_out):\n",
    "#     continue\n",
    "  \n",
    "#   # Extract the embedding using the pre-trained model.\n",
    "#   _, _, embeds = extractor(f'gtzan/wav/{path_in}', model='MSD_musicnn', extract_features=True)\n",
    "#   # Average the embeddings over temporal dimension.\n",
    "#   embed = embeds['max_pool'].mean(axis=0)\n",
    "\n",
    "#   # Save the embedding.\n",
    "#   np.save(path_out, embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "AmgDstz0L_PE"
   },
   "outputs": [],
   "source": [
    "class EmbedDataset(Dataset):\n",
    "  def __init__(self, paths):\n",
    "    self.paths = paths\n",
    "\n",
    "  def __getitem__(self, i):\n",
    "    # Get i-th path.\n",
    "    path = self.paths[i]\n",
    "    # Get i-th embeddding path.\n",
    "    path = 'gtzan/msd_embed/' + path.replace('.wav', '.npy')\n",
    "\n",
    "    # Extract the genre from its path.\n",
    "    genre = path.split('/')[-2]\n",
    "    # Trun the genre into index number.\n",
    "    label = genre_dict[genre]\n",
    "\n",
    "    # Load the mel-spectrogram.\n",
    "    embed = np.load(path)\n",
    "\n",
    "    return embed, label\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "lywWIQj5UgYe"
   },
   "outputs": [],
   "source": [
    "dataset_train = EmbedDataset(train)\n",
    "dataset_test = EmbedDataset(test)\n",
    "\n",
    "num_workers = os.cpu_count()\n",
    "loader_train = DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers, drop_last=True)\n",
    "loader_test = DataLoader(dataset_test, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "iXo3AIaNPvCJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "753"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_size = dataset_train[0][0].shape[0]\n",
    "embed_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yY0snpd1cREq"
   },
   "source": [
    "### [Question 2] Implement, train and evaluate 2-layer MLP using the extracted embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "GNhEh_76Ps25"
   },
   "outputs": [],
   "source": [
    "# TODO: Question 2\n",
    "class Q2(nn.Module):\n",
    "  def __init__(self, hidden_size=32):\n",
    "    super(Q2, self).__init__()\n",
    "    \n",
    "    self.hidden_size = hidden_size\n",
    "    \n",
    "    self.main = nn.Sequential(\n",
    "        nn.Linear(embed_size, hidden_size),\n",
    "        # nn.BatchNorm?\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_size, len(genres))\n",
    "    )\n",
    "    \n",
    "  def forward(self, x):\n",
    "    x = self.main(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.0006\n",
      "    momentum: 0.9\n",
      "    nesterov: True\n",
      "    weight_decay: 0.0\n",
      ")\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "Q2_model = Q2()\n",
    "# Define a loss function, which is cross entropy here.\n",
    "Q2_criterion = torch.nn.CrossEntropyLoss()\n",
    "# Setup an optimizer. Here, we use Stochastic gradient descent (SGD) with a nesterov mementum.\n",
    "Q2_optimizer = torch.optim.SGD(Q2_model.parameters(), lr=LR, momentum=MOMENTUM, nesterov=True, weight_decay=weight_decay)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# Move variables to the desired device.\n",
    "Q2_model.to(device)\n",
    "Q2_criterion.to(device)\n",
    "\n",
    "print(f'Optimizer: {Q2_optimizer}')\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2773145a5ed4ab69b9d94ef3f0a585b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 00', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eaa808a73c54a46b124ccc4f26ad50a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 01', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfebaff103d844a7b27667e907286f0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 02', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4fee27991204992b0bc8f479f8b3d86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 03', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "365ef56ce89b47e481e2f235c5103793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 04', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2bc0348f8534238a6bf702ac69798d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 05', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97593e23ba8d4ad5a0a575beeaa91e25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 06', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18f8f9d0aaee407c83d1d8025b018dcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 07', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6b7e63825764cfaae0fb1c97da33e4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 08', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c7e0d41892c4fdb850bd34d2e83574d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 09', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27843dc71f094232925909162b615751",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 10', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5dad007d23d41649ec6d0bcf0cabc30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 11', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2467a9c27f94adbbdfa22e176780417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 12', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03badc3688ff40d7a78179c349480829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 13', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e28c1f36af14c7d8f0f5e130c559ec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 14', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1ea66199f7f4366ab19d87ef9c2f3d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 15', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "033b4534bbb3430899d7b56b07d3539b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 16', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fce78d013add4b01aa42f73511e50371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 17', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf56b91d1fdc47cdbbc0dac950c542b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 18', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e770ba06516546dcbe6840a838486b1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 19', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42eef3e8fdb04dfa88a5d01f6adbef56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 20', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2d1535815be4cfe9d36aab7714f5706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 21', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "409a3731f7bb4e2e839a71618534e46d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 22', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d81b7b523b44101b273caaba9b63752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 23', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e27db0aa5ee54424b681f45a37d3b25a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 24', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e3c6e0062b94d3b960836cbe086c9c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 25', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dd8bc2c140b43989782b88327480e57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 26', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e141deb469404eb1a610a4597b38a503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 27', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acb0e368e7c3426b8a387f9e1716ba9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 28', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9fac2d66fa2420ba518837c5934953d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 29', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b99b7a33dd7e4b96b1f78b6d979e868e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 30', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4c6efee155c4bffb3a118a6453a7008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 31', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3556428bee24f4fbbf47c24c2019dca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 32', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93ec289fcbbe42d28764ae892467d726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 33', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c3519ed889b47df98885d1a20731489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 34', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "754e0bd84e1c449caf21ab012d781438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 35', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7edb093d21394cd6acabd1131b859d7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 36', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16bf48e11eae41be9d90df21e150d0d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 37', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fd0d5cedd4c40339978b07076cb6110",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 38', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfe6d291ab6149f2bc7a1a29884341bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 39', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f3af805f6ac433e9b0e87981b1ae00b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 40', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a4dd698508449759bcfa600ea755489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 41', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0da23579a5d344959a4971599c58a1a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 42', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9eff603ffe64b2385a7f2987327833c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 43', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf4752001c41486abe17d1613b07956b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 44', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "378517305146440fad74a2d23b7bad2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 45', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbad5c3ca4b94281a8f9505bce61ae76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 46', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35a5c58d6dda4c94a1da0da85e9935e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 47', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98f41cc4184e4e1491dcabd211668f54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 48', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5844ffa4f646474580a1bdc3930b9169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 49', max=145.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the status of the model as training.\n",
    "Q2_model.train()\n",
    "Q2_NUM_EPOCHS = 50\n",
    "# Iterate over epochs.\n",
    "for epoch in range(Q2_NUM_EPOCHS):\n",
    "  epoch_loss = 0\n",
    "  epoch_acc = 0\n",
    "  pbar = tqdm(loader_train, desc=f'Epoch {epoch:02}')  # progress bar\n",
    "  for x, y in pbar:\n",
    "    # Move mini-batch to the desired device.\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    # Feed forward the model.\n",
    "    prediction = Q2_model(x)\n",
    "    # Compute the loss.\n",
    "    loss = Q2_criterion(prediction, y)\n",
    "    # Compute the accuracy.\n",
    "    acc = accuracy(prediction, y)\n",
    "\n",
    "    # Perform backward propagation to compute gradients.\n",
    "    loss.backward()\n",
    "    # Update the parameters.\n",
    "    Q2_optimizer.step()\n",
    "    # Reset the computed gradients.\n",
    "    Q2_optimizer.zero_grad()\n",
    "\n",
    "    # Log training metrics.\n",
    "    batch_size = len(x)\n",
    "    epoch_loss += batch_size * loss.item()\n",
    "    epoch_acc += batch_size * acc\n",
    "    # Update the progress bar.\n",
    "    pbar.set_postfix({'loss': epoch_loss / len(dataset_train), \n",
    "                      'acc': epoch_acc / len(dataset_train)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcd0a5afb6474f13a5a3d424f5ed4099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Test', max=38.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test_loss=1.75042, test_acc=32.00%\n"
     ]
    }
   ],
   "source": [
    "# Set the status of the model as evaluation.\n",
    "Q2_model.eval()\n",
    "\n",
    "# `torch.no_grad()` disables computing gradients. The gradients are still \n",
    "# computed even though you use `model.eval()`. You should use `torch.no_grad()` \n",
    "# if you don't want your memory is overflowed because of unnecesary gradients.\n",
    "with torch.no_grad():\n",
    "  epoch_loss = 0\n",
    "  epoch_acc = 0\n",
    "  pbar = tqdm(loader_test, desc=f'Test')  # progress bar\n",
    "  for x, y in pbar:\n",
    "    # Move mini-batch to the desired device.\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    # Feed forward the model.\n",
    "    prediction = Q2_model(x)\n",
    "    # Compute the loss.\n",
    "    loss = Q2_criterion(prediction, y)\n",
    "    # Compute the accuracy.\n",
    "    acc = accuracy(prediction, y)\n",
    "\n",
    "    # Log training metrics.\n",
    "    batch_size = len(x)\n",
    "    epoch_loss += batch_size * loss.item()\n",
    "    epoch_acc += batch_size * acc\n",
    "    # Update the progress bar.\n",
    "    pbar.set_postfix({'loss': epoch_loss / len(dataset_test), 'acc': epoch_acc / len(dataset_test)})\n",
    "\n",
    "# Compute the evaluation scores.\n",
    "test_loss = epoch_loss / len(dataset_test)\n",
    "test_acc = epoch_acc / len(dataset_test)\n",
    "\n",
    "print(f'test_loss={test_loss:.5f}, test_acc={test_acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "33p0jbUcjZKF"
   },
   "source": [
    "# Improving Algorithms [[Leader Board]](https://docs.google.com/spreadsheets/d/1bzkMFeXABTae7kDJG6QCU_qnP1ppJDoNQLgGz3ksJu0/edit?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ef-Qjx1rdYEY"
   },
   "source": [
    "### [Question 3] Improve the performenace.\n",
    "Now it is your turn. You should improve the baseline code with your own algorithm. There are many ways to improve it. The followings are possible ideas: \n",
    "\n",
    "* The first thing to do is to segment audio clips and generate more data. The baseline code utilizes the whole mel-spectrogram as an input to the network (e.g. 96x936 dimensions). Try to make the network input between 3-5 seconds segment and average the predictions of the segmentations for an audio clip.\n",
    "\n",
    "* You can try training a model using both mel-spectrograms and features extracted using the pre-trained models. The baseline code is using a pre-trained model trained on 19k songs, but `musicnn` also has models trained on 200k songs! Try using the model giving `model='MSD_musicnn'` option on feature extraction.\n",
    "\n",
    "* You can try 1D CNN or 2D CNN models and choose different model parameters:\n",
    "    * Filter size\n",
    "    * Pooling size\n",
    "    * Stride size \n",
    "    * Number of filters\n",
    "    * Model depth\n",
    "    * Regularization: L2/L1 and Dropout\n",
    "\n",
    "* You should try different hyperparameters to train the model and optimizers:\n",
    "    * Learning rate\n",
    "    * Model depth\n",
    "    * Optimizers: SGD (with Nesterov momentum), Adam, RMSProp, ...\n",
    "\n",
    "* You can try different parameters (e.g. hop and window size) to extract mel-spectrogram or different features as input to the network (e.g. MFCC, chroma features ...). \n",
    "\n",
    "* You can also use ResNet or other CNNs with skip connections. \n",
    "\n",
    "* Furthermore, you can augment data using digital audio effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "AqTgCmU5h32G"
   },
   "outputs": [],
   "source": [
    "# TODO: Question 3\n",
    "class Q3(nn.Module):\n",
    "  def __init__(self, hidden_size=32):\n",
    "    super(Q3, self).__init__()\n",
    "    \n",
    "    self.hidden_size = hidden_size\n",
    "    \n",
    "    self.main = nn.Sequential(\n",
    "        nn.Linear(embed_size, hidden_size),\n",
    "        # nn.BatchNorm?\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_size, len(genres))\n",
    "    )\n",
    "    \n",
    "  def forward(self, x):\n",
    "    x = self.main(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CRfOAefCh57y"
   },
   "source": [
    "\n",
    "# Deliverables\n",
    "You should submit your Python code (`.ipynb` or `.py` files) and homework report (.pdf file) to KLMS. The report should include:\n",
    "* Algorithm Description\n",
    "* Experiments and Results\n",
    "* Discussion\n",
    "\n",
    "# Note\n",
    "The code is written using PyTorch but you can use TensorFlow if you want for question 3.\n",
    "\n",
    "# Credit\n",
    "Thie homework was implemented by Jongpil Lee, Soonbeom Choi and Taejun Kim in the KAIST Music and Audio Computing Lab.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "GCT634/AI613 (Fall 2020) HW#2 Colab Notebook",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
